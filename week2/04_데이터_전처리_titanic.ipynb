{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f56f47-be8a-423a-999b-153301523d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DT, RF, SVM, LR, K-NN \n",
    "# titanic.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "819f10cc-d3c9-40ea-a170-5881aa5f8368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "나이의 평균값 :  29.69911764705882\n",
      "     PassengerId  Pclass  Sex        Age  SibSp  Parch     Fare\n",
      "0              1       3    1  22.000000      1      0   7.2500\n",
      "1              2       1    0  38.000000      1      0  71.2833\n",
      "2              3       3    0  26.000000      0      0   7.9250\n",
      "3              4       1    0  35.000000      1      0  53.1000\n",
      "4              5       3    1  35.000000      0      0   8.0500\n",
      "..           ...     ...  ...        ...    ...    ...      ...\n",
      "886          887       2    1  27.000000      0      0  13.0000\n",
      "887          888       1    0  19.000000      0      0  30.0000\n",
      "888          889       3    0  29.699118      1      2  23.4500\n",
      "889          890       1    1  26.000000      0      0  30.0000\n",
      "890          891       3    1  32.000000      0      0   7.7500\n",
      "\n",
      "[891 rows x 7 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\TempFolder\\ipykernel_13760\\1435106048.py:22: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X['Sex'] = df['Sex'].replace({'male': 1, 'female': 0})\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Decision Tree Accuracy: 0.7039\n",
      "2. Random Forest Accuracy: 0.7821\n",
      "3. Support Vector Machine Accuracy: 0.5978\n",
      "4. Logistic Regression Accuracy: 0.7765\n",
      "K-NN Classification 예측 결과: [0 0 0 1 0 1 1 0 1 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 1 0 0 0\n",
      " 1 1 0 0 0 0 0 1 0 0 0 0 0 1 1 0 1 0 1 1 1 1 1 0 1 1 0 0 1 0 0 1 1 1 1 0 1\n",
      " 0 0 1 1 1 1 0 1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 1 0 0 1 1 0 0 0 1 0 0 0 1\n",
      " 0 1 0 0 0 0 0 1 1 1 1 1 1 0 1 1 0 1 0 1 0 0 1 1 0 1 0 0 0 0 1 0 0 0 1 0 0\n",
      " 1 0 0 0 0 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 0 0 0 1 1 1 0 0 0 1 0]\n",
      "5. K-NN Classification 정확도: 0.80\n",
      "최적의 K 값: 1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# 0. CSV 파일 불러오기\n",
    "file = \"C:/AI/titanic.csv\"  # CSV 파일 경로\n",
    "df = pd.read_csv(file)\n",
    "\n",
    "# 1. 데이터 전처리 (X: 특성, y: 타겟)\n",
    "X = df.drop(columns=['Survived', 'Name', 'Ticket', 'Cabin', 'Embarked'])\n",
    "y = df[\"Survived\"]\n",
    "print(\"나이의 평균값 : \", df['Age'].mean())\n",
    "X['Age'] = df['Age'].fillna(df['Age'].mean())\n",
    "X['Sex'] = df['Sex'].replace({'male': 1, 'female': 0})\n",
    "print(X)\n",
    "\n",
    "# 2. 데이터 분할 (훈련 80%, 테스트 20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 4. 모델 학습\n",
    "model_DT = DecisionTreeClassifier() \n",
    "model_RF = RandomForestClassifier()\n",
    "model_SVM = SVC()\n",
    "model_LR = LogisticRegression()\n",
    "\n",
    "model_DT.fit(X_train, y_train)\n",
    "model_RF.fit(X_train, y_train)\n",
    "model_SVM.fit(X_train, y_train)\n",
    "model_LR.fit(X_train, y_train)\n",
    "\n",
    "# 5. 예측 및 정확도 평가\n",
    "y_pred_DT = model_DT.predict(X_test)\n",
    "accuracy_DT = accuracy_score(y_test, y_pred_DT)\n",
    "print(f\"1. Decision Tree Accuracy: {accuracy_DT:.4f}\")\n",
    "\n",
    "y_pred_RF = model_RF.predict(X_test)\n",
    "accuracy_RF = accuracy_score(y_test, y_pred_RF)\n",
    "print(f\"2. Random Forest Accuracy: {accuracy_RF:.4f}\")\n",
    "\n",
    "y_pred_SVM = model_SVM.predict(X_test)\n",
    "accuracy_SVM = accuracy_score(y_test, y_pred_SVM)\n",
    "print(f\"3. Support Vector Machine Accuracy: {accuracy_SVM:.4f}\")\n",
    "\n",
    "y_pred_LR = model_LR.predict(X_test)\n",
    "accuracy_LR = accuracy_score(y_test, y_pred_LR)\n",
    "print(f\"4. Logistic Regression Accuracy: {accuracy_LR:.4f}\")\n",
    "\n",
    "# 5. K-NN 모델 학습 (K=2)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=3)\n",
    "knn_clf.fit(X_train, y_train)\n",
    "y_pred_class = knn_clf.predict(X_test)\n",
    "print(\"K-NN Classification 예측 결과:\", y_pred_class)\n",
    "\n",
    "accuracy = knn_clf.score(X_test, y_test)\n",
    "print(f\"5. K-NN Classification 정확도: {accuracy:.2f}\")\n",
    "\n",
    "k_values = range(1, 21)  # K값 범위 설정\n",
    "scores = []\n",
    "\n",
    "for k in k_values:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)  # K-NN 모델 생성\n",
    "    knn.fit(X_train, y_train)  # 학습\n",
    "    y_pred = knn.predict(X_test)  # 예측\n",
    "    accuracy = accuracy_score(y_test, y_pred)  # 정확도 계산\n",
    "    scores.append(accuracy)\n",
    "\n",
    "# 최적의 K 값 찾기\n",
    "best_k = k_values[np.argmax(scores)]\n",
    "print(f\"최적의 K 값: {best_k}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d6d8b4-baac-426d-b10e-8f93862a38fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
